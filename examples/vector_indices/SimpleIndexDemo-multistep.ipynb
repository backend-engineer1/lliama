{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c48213d-6e6a-4c10-838a-2a7c710c3a05",
   "metadata": {},
   "source": [
    "# Simple Index Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3b817-b70e-4667-be4f-d3a0fe4bd119",
   "metadata": {},
   "source": [
    "#### Load documents, build the GPTSimpleVectorIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690a6918-7c75-4f95-9ccc-d2c4a1fe00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from gpt_index import (\n",
    "    GPTSimpleVectorIndex, \n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48da73f-aadb-480c-8db1-99c915b7cc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM Predictor (gpt-3)\n",
    "llm_predictor_gpt3 = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\"))\n",
    "\n",
    "# LLMPredictor (gpt-4)\n",
    "llm_predictor_gpt4 = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d1691e-544b-454f-825b-5ee12f7faa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader('../paul_graham_essay/data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad144ee7-96da-4dd6-be00-fd6cf0c78e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 17598 tokens\n",
      "> [build_index_from_documents] Total embedding token usage: 17598 tokens\n",
      "> [build_index_from_documents] Total embedding token usage: 17598 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTSimpleVectorIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bbccf1d-ac39-427c-b3a3-f8e9d1d12348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "index.save_to_disk('index_simple.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197ca78e-1310-474d-91e3-877c3636b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from disk\n",
    "index = GPTSimpleVectorIndex.load_from_disk('index_simple.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6caf93b-6345-4c65-a346-a95b0f1746c4",
   "metadata": {},
   "source": [
    "#### Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d989ba-0c1d-43b6-a1d3-0ea7135f43a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gpt_index.indices.query.query_transform.base import StepDecomposeQueryTransform\n",
    "# gpt-4\n",
    "step_decompose_transform = StepDecomposeQueryTransform(\n",
    "    llm_predictor_gpt4, verbose=True\n",
    ")\n",
    "\n",
    "# gpt-3\n",
    "step_decompose_transform_gpt3 = StepDecomposeQueryTransform(\n",
    "    llm_predictor_gpt3, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a124db0-e2d7-4566-bcec-1d41cf669ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index.set_text(\"Used to answer questions about the author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85466fdf-93f3-4cb1-a5f9-0056a8245a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m> Current query: Who was in the first batch of the accelerator program the author started?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: Who was in the first batch of the accelerator program the author started?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: Who was in the first batch of the accelerator program the author started?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: None\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: What accelerator program did the author start?\n",
      "\u001b[0mINFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 3649 tokens\n",
      "> [query] Total LLM token usage: 3649 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n",
      "\u001b[33;1m\u001b[1;3m> Current query: Who was in the first batch of the accelerator program the author started?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: Who was in the first batch of the accelerator program the author started?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: Who was in the first batch of the accelerator program the author started?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: \n",
      "- What accelerator program did the author start?\n",
      "- The author started the accelerator program called Y Combinator (YC), which focuses on supporting and funding new startups every six months.\n",
      "\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: Who was in the first batch of Y Combinator's accelerator program?\n",
      "\u001b[0mINFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 3864 tokens\n",
      "> [query] Total LLM token usage: 3864 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n",
      "\u001b[33;1m\u001b[1;3m> Current query: Who was in the first batch of the accelerator program the author started?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: Who was in the first batch of the accelerator program the author started?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: Who was in the first batch of the accelerator program the author started?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: \n",
      "- What accelerator program did the author start?\n",
      "- The author started the accelerator program called Y Combinator (YC), which focuses on supporting and funding new startups every six months.\n",
      "- Who was in the first batch of Y Combinator's accelerator program?\n",
      "- The first batch of Y Combinator's accelerator program, which started in 2005, included startups like Reddit, founded by Steve Huffman and Alexis Ohanian; Justin Kan and Emmett Shear, who later founded Twitch; Aaron Swartz, who had already helped write the RSS spec and would later become a martyr for open access; and Sam Altman, who would later become the second president of YC. These startups and their founders faced various challenges during the program, and their problems became Y Combinator's problems, leading to a highly engaging and dynamic work environment.\n",
      "\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: Who were the founders and startups in the first batch of Y Combinator's accelerator program?\n",
      "\u001b[0mINFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 3882 tokens\n",
      "> [query] Total LLM token usage: 3882 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n"
     ]
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "response_gpt4 = index.query(\n",
    "    \"Who was in the first batch of the accelerator program the author started?\",\n",
    "    query_transform=step_decompose_transform,\n",
    "    llm_predictor=llm_predictor_gpt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdda1b2c-ae46-47cf-91d7-3153e8d0473b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "\n",
       "The first batch of the Y Combinator accelerator program included startups such as Reddit (founded by Steve Huffman and Alexis Ohanian), Loopt, Weebly, Twitch (founded by Justin Kan and Emmett Shear), and Aaron Swartz (who had already helped write the RSS spec and would later become a martyr for open access). This initial group of startups was supported by Y Combinator with funding, mentorship, and resources to help them grow their businesses, and Sam Altman, who would later become the second president of YC, was also part of this batch.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response_gpt4}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c9670bd-729d-478b-a77c-c6e13c282456",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What accelerator program did the author start?', 'The author started the accelerator program called Y Combinator (YC), which focuses on supporting and funding new startups every six months.'), (\"Who was in the first batch of Y Combinator's accelerator program?\", \"The first batch of Y Combinator's accelerator program, which started in 2005, included startups like Reddit, founded by Steve Huffman and Alexis Ohanian; Justin Kan and Emmett Shear, who later founded Twitch; Aaron Swartz, who had already helped write the RSS spec and would later become a martyr for open access; and Sam Altman, who would later become the second president of YC. These startups and their founders faced various challenges during the program, and their problems became Y Combinator's problems, leading to a highly engaging and dynamic work environment.\"), (\"Who were the founders and startups in the first batch of Y Combinator's accelerator program?\", \"The first batch of Y Combinator's accelerator program, which took place in 2005, included startups like Reddit, founded by Steve Huffman and Alexis Ohanian; Kiko, founded by Justin Kan and Emmett Shear (who later founded Twitch); Infogami, founded by Aaron Swartz (who had helped write the RSS spec and later became a martyr for open access); and Loopt, founded by Sam Altman (who later became the second president of YC). These founders and their startups were part of the initial group that Y Combinator supported, and their problems and challenges became the focus of the accelerator program during that first batch.\")]\n"
     ]
    }
   ],
   "source": [
    "sub_qa = response_gpt4.extra_info[\"sub_qa\"]\n",
    "tuples = [(t[0], t[1].response) for t in sub_qa]\n",
    "print(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec88df57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: None\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: Who is the author that founded Viaweb?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3684 tokens\n",
      "> [query] Total LLM token usage: 3684 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n",
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: \n",
      "- Who is the author that founded Viaweb?\n",
      "- Paul Graham is the author who founded Viaweb.\n",
      "\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: In which city did Paul Graham found his first company, Viaweb?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3698 tokens\n",
      "> [query] Total LLM token usage: 3698 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n",
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: \n",
      "- Who is the author that founded Viaweb?\n",
      "- Paul Graham is the author who founded Viaweb.\n",
      "- In which city did Paul Graham found his first company, Viaweb?\n",
      "- Paul Graham founded his first company, Viaweb, in Cambridge.\n",
      "\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: None\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response_gpt4 = index.query(\n",
    "    \"In which city did the author found his first company, Viaweb?\",\n",
    "    query_transform=step_decompose_transform,\n",
    "    llm_predictor=llm_predictor_gpt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653508f1-b2b0-479a-85b3-113cda507231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer: Paul Graham founded his first company, Viaweb, in Cambridge, Massachusetts.\n"
     ]
    }
   ],
   "source": [
    "print(response_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fa93cdb-7007-4664-853a-5c81c6c17560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: None\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  Where was the author located when he founded his first company, Viaweb?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3724 tokens\n",
      "> [query] Total LLM token usage: 3724 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n",
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: \n",
      "-  Where was the author located when he founded his first company, Viaweb?\n",
      "- \n",
      "\n",
      "The author was located in Cambridge, Massachusetts when he founded his first company, Viaweb.\n",
      "\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  Where is Cambridge, Massachusetts located?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3778 tokens\n",
      "> [query] Total LLM token usage: 3778 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n",
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: \n",
      "-  Where was the author located when he founded his first company, Viaweb?\n",
      "- \n",
      "\n",
      "The author was located in Cambridge, Massachusetts when he founded his first company, Viaweb.\n",
      "-  Where is Cambridge, Massachusetts located?\n",
      "- \n",
      "\n",
      "Cambridge, Massachusetts is located in the Greater Boston area of the northeastern United States. It is situated directly north of Boston, across the Charles River. Paul Graham, the creator of the Lisp programming language, bought a house in Cambridge in the late 1990s and used it as a base for his work on the language.\n",
      "\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: \n",
      "Where is Paul Graham's house located in Cambridge, Massachusetts?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3719 tokens\n",
      "> [query] Total LLM token usage: 3719 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n"
     ]
    }
   ],
   "source": [
    "response_gpt3 = index.query(\n",
    "    \"In which city did the author found his first company, Viaweb?\",\n",
    "    query_transform=step_decompose_transform_gpt3,\n",
    "    llm_predictor=llm_predictor_gpt3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05899fcf-7a04-4d21-9e6d-04983755d175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The author founded his first company, Viaweb, in Cambridge, Massachusetts, which is located in the Greater Boston area of the northeastern United States, directly north of Boston, across the Charles River. Paul Graham, the creator of the Lisp programming language, bought a house in Cambridge in the spring of 1995 to work on a new dialect of Lisp called Arc, and used it as a base for his work on the language.\n"
     ]
    }
   ],
   "source": [
    "print(response_gpt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43c659-ffd0-40df-b52b-032e6647cf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fedcd46b",
   "metadata": {},
   "source": [
    "# Llama Debug Handler Demo\n",
    "\n",
    "Here we showcase the capabilities of our LlamaDebugHandler in logging events as we run queries\n",
    "within LlamaIndex.\n",
    "\n",
    "**NOTE**: This is a beta feature. The usage within different classes and the API interface\n",
    "    for the CallbackManager and LlamaDebugHandler may change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e94187d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/langchain/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler, CBEventType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d93af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTListIndex, ServiceContext, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e1e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = SimpleDirectoryReader(\"../paul_graham_essay/data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34d08b",
   "metadata": {},
   "source": [
    "## Callback Manager Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c667d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_debug = LlamaDebugHandler()\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "service_context = ServiceContext.from_defaults(callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25851e27",
   "metadata": {},
   "source": [
    "## Trigger the callback with a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66db8c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTListIndex.from_documents(docs, service_context=service_context)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d4840b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [get_response] Total LLM token usage: 28944 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e69b186",
   "metadata": {},
   "source": [
    "## Explore the Debug Information\n",
    "\n",
    "The callback manager will log several start and end events for the following types:\n",
    "- CBEventType.LLM\n",
    "- CBEventyType.EMBEDDING\n",
    "- CBEventType.CHUNKING\n",
    "- CBEventType.RETRIEVE\n",
    "- CBEventType.SYNTHESIZE \n",
    "- CBEventType.TREE\n",
    "- CBEventType.QUERY\n",
    "\n",
    "The LlamaDebugHandler provides a few basic methods for exploring information about these events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a4ba2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EventStats(total_secs=161.0, average_secs=13.416666666666666, total_count=12)\n"
     ]
    }
   ],
   "source": [
    "# Print info on the LLM calls during the list index query\n",
    "print(llama_debug.get_event_time_info(CBEventType.LLM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4831a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBEvent(event_type=<CBEventType.LLM: 'llm'>, payload=None, time='05/01/2023, 19:58:56', id_='1fd2e2c5-a334-47cc-9f81-188035825633')\n",
      "dict_keys(['stage', 'response', 'formatted_prompt'])\n",
      "\n",
      "Growing up, the author wrote short stories, programmed on an IBM 1401, and wrote programs for a TRS-80 microcomputer. He wrote simple games, a program to predict how high his model rockets would fly, and a word processor. He also studied philosophy in college, but switched to AI when he realized it was a more exciting field. He reverse-engineered SHRDLU for his undergraduate thesis, and wrote a book about Lisp hacking while in grad school. He also took art classes at Harvard and applied to art schools.\n"
     ]
    }
   ],
   "source": [
    "# Print info on llm inputs/outputs - returns start/end events for each LLM call\n",
    "event_pairs = llama_debug.get_llm_inputs_outputs()\n",
    "print(event_pairs[0][0])\n",
    "print(event_pairs[0][1].payload.keys())\n",
    "print(event_pairs[0][1].payload['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf70da51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['documents'])\n",
      "dict_keys(['nodes'])\n"
     ]
    }
   ],
   "source": [
    "# Get info on any event type\n",
    "event_pairs = llama_debug.get_event_pairs(CBEventType.CHUNKING)\n",
    "print(event_pairs[0][0].payload.keys())  # get first chunking start event\n",
    "print(event_pairs[0][1].payload.keys())  # get first chunking end event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "449af1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the currently cached events\n",
    "llama_debug.flush_event_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde936fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

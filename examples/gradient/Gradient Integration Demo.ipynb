{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9f19f3",
   "metadata": {},
   "source": [
    "# LlamaIndex / Gradient Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a726c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/hayden/llama_index/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/hayden/llama_index/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index --quiet\n",
    "%pip install gradientai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2b0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GRADIENT_ACCESS_TOKEN\"] = \"{GRADIENT_ACCESS_TOKEN}\"\n",
    "os.environ[\"GRADIENT_WORKSPACE_ID\"] = \"{GRADIENT_WORKSPACE_ID}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a602a2a",
   "metadata": {},
   "source": [
    "## Flow 1: Query Gradient LLM directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4baffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import GradientBaseModelLLM\n",
    "\n",
    "# You can also use a model adapter you've trained with GradientModelAdapterLLM\n",
    "llm = GradientBaseModelLLM(\n",
    "    base_model_slug=\"llama2-7b-chat\",\n",
    "    max_tokens=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7039a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Large language models are artificial intelligence (AI) models that are trained on vast amounts of text data to generate language outputs that are coherent and natural-sounding. These models have become increasingly popular in recent years due to their ability to generate text that is often indistinguishable from human-written text. In this answer, I will provide an overview of large language models, including their types, applications, and potential uses.\n",
      "\n",
      "Types of Large Language Models:\n",
      "\n",
      "1. Generative Adversarial Networks (GANs): GANs are a type of deep learning model that consists of two neural networks: a generator and a discriminator. The generator creates text, while the discriminator evaluates the generated text and provides feedback to the generator. The goal of the generator is to produce text that is indistinguishable from human-written text, while the goal of the discriminator is to correctly identify whether the text was generated by a human or a machine.\n",
      "2. Transformers: Transformers are a type of neural network architecture that are particularly well-suited for natural language processing tasks. They consist of an encoder and a decoder, which work together to generate text. Transformers are known for their ability to handle long-range dependencies in text, making them particularly useful for tasks such as language translation.\n",
      "3. Recurrent Neural Networks (RNNs): RNNs are a type of neural network that are particularly well-suited for sequential data such as text. They use a feedback loop to maintain a hidden state that captures information from previous time steps, allowing them to generate text that is contextually appropriate.\n",
      "\n",
      "Applications of Large Language Models:\n",
      "\n",
      "1. Language Translation: Large language models can be trained on large datasets of text in multiple languages, allowing them to learn the patterns and structures of\n"
     ]
    }
   ],
   "source": [
    "result = llm.complete(\"Can you tell me about large language models?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1112e828",
   "metadata": {},
   "source": [
    "## Flow 2: Retrieval Augmented Generation (RAG) with Gradient LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacff36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.embeddings import LangchainEmbedding\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd41d1",
   "metadata": {},
   "source": [
    "### Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5941151",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"../paul_graham_essay/data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4407f",
   "metadata": {},
   "source": [
    "### Configure Gradient LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec73a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayden/llama_index/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embed_model = LangchainEmbedding(HuggingFaceEmbeddings())\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    chunk_size=1024, llm=llm, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a131a8e",
   "metadata": {},
   "source": [
    "### Setup and Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b10269",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac73eb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After his time at Y Combinator, the author continued to work on YC, helping to get the next batch of startups through Demo Day before checking out completely. He was particularly fascinated by SHRDLU, a language model developed by Terry Winograd, and spent a significant amount of time working with it, drawn entirely into its world. It seemed only a matter of time before he would have Mike, and when he saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All he had to do was teach SHRDLU more words.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the author do after his time at Y Combinator?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ae9fa2777630f93d325d67fd0c37f7375ed1afcb20dd85f425eb8692a47ff3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

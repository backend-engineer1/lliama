{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025f3e20-aec9-491c-8c90-234aed406a25",
   "metadata": {},
   "source": [
    "# Recursive Retriever + Node References\n",
    "\n",
    "This guide shows how you can use recursive retrieval to traverse node relationships and fetch nodes based on \"references\".\n",
    "\n",
    "Node references are a powerful concept. When you first perform retrieval, you may want to retrieve the reference as opposed to the raw text. You can have multiple references point to the same node.\n",
    "\n",
    "In this guide we explore some different usages of node references:\n",
    "- **Chunk references**: Different chunk sizes referring to a bigger chunk\n",
    "- **Metadata references**: Summaries + Generated Questions referring to a bigger chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee583e89-a508-493e-b232-42e520ce19de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f38de-e79a-4ce2-ad4e-2c70afc33f34",
   "metadata": {},
   "source": [
    "## Load Data + Setup\n",
    "\n",
    "In this section we download the Llama 2 paper and create an initial set of nodes (chunk size 1024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb829ef-b54b-4095-a832-6d1d115aa645",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd97455-5ff3-43ee-8222-f496ec234dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_hub.file.pdf.base import PDFReader\n",
    "from llama_index.response.notebook_utils import display_source_node\n",
    "from llama_index.retrievers import RecursiveRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07c0e42-1ae8-4267-9355-6bb75323f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFReader()\n",
    "docs0 = loader.load_data(file=Path(\"./data/llama2.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "493e5492-a6ae-4e3e-aa23-274c0605b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n",
    "docs = [Document(text=doc_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2abcd3-6cae-49dd-8719-9b738d000652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.schema import IndexNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b997ae-9260-4ae7-af2f-0f8d38625d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cda44b0-fd27-4255-9aa7-08d358635772",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes = node_parser.get_nodes_from_documents(docs)\n",
    "# set node ids to be a constant\n",
    "for idx, node in enumerate(base_nodes):\n",
    "    node.id_ = f\"node-{idx}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e47623-b67d-45d6-9b24-33ba84719f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import resolve_embed_model\n",
    "\n",
    "embed_model = resolve_embed_model(\"local:BAAI/bge-small-en\")\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ebab2-fc46-41ea-8a92-9148994d793f",
   "metadata": {},
   "source": [
    "## Baseline Retriever\n",
    "\n",
    "Define a baseline retriever that simply fetches the top-k raw text nodes by embedding similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "704fb3da-710e-4ad9-b630-565911917f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index = VectorStoreIndex(base_nodes, service_context=service_context)\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160c339b-601a-486b-9e17-dd6cc9f133ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievals = base_retriever.retrieve(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "632610f3-c8f2-440a-ab27-5ca7d65f882a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-22<br>**Similarity:** 0.8486295634691985<br>**Text:** We observe that models\n",
       "trained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\n",
       "safety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\n",
       "be applied before deployment of base Llama 2 models.\n",
       "22\n",
       "\n",
       "TruthfulQA ↑ToxiGen ↓\n",
       "MPT7B 29.13 22.32\n",
       "30B 35.25 22.61\n",
       "Falcon7B 25.95 14.53\n",
       "40B 40.39 23.44\n",
       "Llama 17B 27.42 23.00\n",
       "13B 41.74 23.08\n",
       "33B 44.19 22.57\n",
       "65B 48.71 21.77\n",
       "Llama 27B 33.29 21.25\n",
       "13B 41.86 26.10\n",
       "34B 43.45 21.19\n",
       "70B 50.18 24.60\n",
       "Table 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\n",
       "percentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\n",
       "present the percentage of toxic generations (the smaller, the better).\n",
       "Benchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\n",
       "patternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\n",
       "onpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\n",
       "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
       "in which a system may be deployed. For this, it may be necessary to test beyond the groups available in\n",
       "theBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\n",
       "continuing research that will amplify their potential for positive impact on these important social issues.\n",
       "4.2 Safety Fine-Tuning\n",
       "In...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-65<br>**Similarity:** 0.8475738620825305<br>**Text:** Theassis-\n",
       "tant’sanswersshouldnotincludeanyharmful,unethical,orsociallybiasedcontent,andshouldmovethe\n",
       "conversation in a positive direction.\n",
       "(Based on a specific risk category) The following is a question that can elicit unsafe behavior from you. The\n",
       "question was classified as belonging to the violating category: ‘Criminal / Fraudulent Content’. You should\n",
       "answer using the following template:\n",
       "1. [ifapplicable]Addressimmediatesafetyconcerns. Forexample,iftheuserdiscussescommittingaviolent\n",
       "crime, the model should point them towards law enforcement resources.\n",
       "2. Addresstheprompt. themodelshouldrefusetoanswerthepromptasgiven,statingthatitviolatesits\n",
       "policy to commit, advise or give information on illegal activities.\n",
       "3. Add context and additional information. If applicable, the model can advise on legal alternatives.\n",
       "4. Encourageuserstoaskfor/viewadditionalinfoasappropriate. Ifapplicable,themodelcanencouragethe\n",
       "user to refine their prompt so that it does not contain any illegal requests or activities.\n",
       "(Based on a specific risk category) The following is a question that can elicit unsafe behavior from you. The\n",
       "questionwasclassified asbelongingtotheviolatingcategory: ‘ExplicitContent’. Youshould answerusing\n",
       "the following template:\n",
       "1. Address immediate safety concerns. For example, if a prompt states the user is a victim of violence or\n",
       "abuse, the model should provide support resources in an empathetic tone.\n",
       "2. Address the prompt. the model should refuse to generate explicit sexual o...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n in retrievals:\n",
    "    display_source_node(n, source_length=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96dd8a01-1cae-4614-beab-5b5e0434fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_base = RetrieverQueryEngine.from_args(\n",
    "    base_retriever, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ae66ff-7d12-45c8-9b1a-adb20bd3c7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key concepts for safety fine-tuning include supervised safety fine-tuning, safety RLHF (Reinforcement Learning from Human Feedback), and safety context distillation. Supervised safety fine-tuning involves gathering adversarial prompts and safe demonstrations to train the model to align with safety guidelines. Safety RLHF integrates safety into the general RLHF pipeline by training a safety-specific reward model and gathering challenging adversarial prompts for fine-tuning. Safety context distillation involves generating safer model responses by prefixing a prompt with a safety preprompt and fine-tuning the model on the safer responses without the preprompt. These techniques aim to mitigate safety risks and ensure that the model's answers do not include harmful, unethical, or socially biased content.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_base.query(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5431df3-d255-4492-bce4-bbebde6f2306",
   "metadata": {},
   "source": [
    "## Chunk References: Smaller Child Chunks Referring to Bigger Parent Chunk\n",
    "\n",
    "In this usage example, we show how to build a graph of smaller chunks pointing to bigger parent chunks.\n",
    "\n",
    "During query-time, we retrieve smaller chunks, but we follow references to bigger chunks. This allows us to have more context for synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c784d8-71e6-42bc-84d9-a2aea4217b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_chunk_sizes = [128, 256, 512]\n",
    "sub_node_parsers = [\n",
    "    SimpleNodeParser.from_defaults(chunk_size=c) for c in sub_chunk_sizes\n",
    "]\n",
    "\n",
    "all_nodes = []\n",
    "for base_node in base_nodes:\n",
    "    for n in sub_node_parsers:\n",
    "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
    "        sub_inodes = [\n",
    "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
    "        ]\n",
    "        all_nodes.extend(sub_inodes)\n",
    "\n",
    "    # also add original node to node\n",
    "    base_inode = IndexNode.from_text_node(base_node, base_node.node_id)\n",
    "    all_nodes.append(base_inode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d614088-b122-40ad-811a-29cc0c2a295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in all_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a44ef2d5-0342-4073-831f-f35dd6f04dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_chunk = VectorStoreIndex(all_nodes, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06af99f-02be-4055-a6ea-3071ffe8fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c7c5e43-45b5-42d6-afc5-cb81ed3cb211",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e9f7bcb-5442-4d2d-a7eb-814b68ebb45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: node-1\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id node-1: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: node-22\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id node-22: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-1<br>**Similarity:** 0.8730185735901727<br>**Text:** . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n",
       "3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n",
       "4 Safety 20\n",
       "4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n",
       "4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n",
       "4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n",
       "4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n",
       "5 Discussion 32\n",
       "5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n",
       "5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n",
       "5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n",
       "6 Related Work 35\n",
       "7 Conclusion 36\n",
       "A Appendix 46\n",
       "A.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n",
       "A.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n",
       "A.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . .<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-22<br>**Similarity:** 0.8656067057400358<br>**Text:** We observe that models\n",
       "trained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\n",
       "safety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\n",
       "be applied before deployment of base Llama 2 models.\n",
       "22\n",
       "\n",
       "TruthfulQA ↑ToxiGen ↓\n",
       "MPT7B 29.13 22.32\n",
       "30B 35.25 22.61\n",
       "Falcon7B 25.95 14.53\n",
       "40B 40.39 23.44\n",
       "Llama 17B 27.42 23.00\n",
       "13B 41.74 23.08\n",
       "33B 44.19 22.57\n",
       "65B 48.71 21.77\n",
       "Llama 27B 33.29 21.25\n",
       "13B 41.86 26.10\n",
       "34B 43.45 21.19\n",
       "70B 50.18 24.60\n",
       "Table 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\n",
       "percentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\n",
       "present the percentage of toxic generations (the smaller, the better).\n",
       "Benchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\n",
       "patternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\n",
       "onpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\n",
       "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
       "in which a system may be deployed. For this, it may be necessary to test beyond the groups available in\n",
       "theBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\n",
       "continuing research that will amplify their potential for positive impact on these important social issues.\n",
       "4.2 Safety Fine-Tuning\n",
       "In this section, we describe our approach to safety fine-tuning, including safety categories, annotation\n",
       "guidelines,andthetechniquesweusetomitigatesafetyrisks. Weemployaprocesssimilartothegeneral\n",
       "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\n",
       "Specifically, we use the following techniques in safety fine-tuning:\n",
       "1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\n",
       "tions that are then included in...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever_chunk.retrieve(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "411f26ad-d13b-4858-938e-efcfa899e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_chunk = RetrieverQueryEngine.from_args(\n",
    "    retriever_chunk, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd98366-0d5f-4d04-87cd-b811990b7485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: node-1\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id node-1: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: node-22\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id node-22: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0mThe key concepts for safety fine-tuning include supervised safety fine-tuning, safety RLHF (Reinforcement Learning from Human Feedback), and safety context distillation. \n",
      "\n",
      "In supervised safety fine-tuning, adversarial prompts and safe demonstrations are gathered and included in the general supervised fine-tuning process. This helps the model align with safety guidelines even before RLHF and lays the foundation for high-quality human preference data annotation.\n",
      "\n",
      "Safety RLHF involves integrating safety into the general RLHF pipeline. This includes training a safety-specific reward model and gathering more challenging adversarial prompts for rejection sampling style fine-tuning and PPO (Proximal Policy Optimization) optimization.\n",
      "\n",
      "Safety context distillation is the final step in safety fine-tuning. It involves refining the RLHF pipeline with context distillation, which generates safer model responses by prefixing a prompt with a safety preprompt. The model is then fine-tuned on the safer responses without the preprompt, effectively distilling the safety preprompt (context) into the model. A targeted approach is used to allow the safety reward model to choose whether to use context distillation for each sample.\n",
      "\n",
      "These concepts are used to mitigate safety risks and improve the safety alignment of the model during the fine-tuning process.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_chunk.query(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc7379-c077-40b7-ba4e-f47f80def0c7",
   "metadata": {},
   "source": [
    "## Metadata References: Summaries + Generated Questions referring to a bigger chunk\n",
    "\n",
    "In this usage example, we show how to define additional context that references the source node.\n",
    "\n",
    "This additional context includes summaries as well as generated questions.\n",
    "\n",
    "During query-time, we retrieve smaller chunks, but we follow references to bigger chunks. This allows us to have more context for synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24e40c5e-4868-487f-aaf4-f333aa4bda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.schema import IndexNode\n",
    "from llama_index.node_parser.extractors import (\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    MetadataExtractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c5d6f87-790e-4b82-abb2-cc6944678b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_extractor = MetadataExtractor(\n",
    "    extractors=[\n",
    "        SummaryExtractor(summaries=[\"self\"], show_progress=True),\n",
    "        QuestionsAnsweredExtractor(questions=5, show_progress=True),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e47c706c-940e-499d-b742-eaf09a230b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006735801696777344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 37,
       "postfix": null,
       "prefix": "Extracting summaries",
       "rate": null,
       "total": 80,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4debb9a3a71843acaebdb1c1e460a482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting summaries:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008962154388427734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 37,
       "postfix": null,
       "prefix": "Extracting questions",
       "rate": null,
       "total": 80,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7aab33b8d134dc48989d9d120c3a466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting questions:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run metadata extractor across base nodes, get back dictionaries\n",
    "metadata_dicts = metadata_extractor.extract(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2873327d-420a-4778-a83b-6fdf7aa21bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache metadata dicts\n",
    "def save_metadata_dicts(path):\n",
    "    with open(path, \"w\") as fp:\n",
    "        for m in metadata_dicts:\n",
    "            fp.write(json.dumps(m) + \"\\n\")\n",
    "\n",
    "\n",
    "def load_metadata_dicts(path):\n",
    "    with open(path, \"r\") as fp:\n",
    "        metadata_dicts = [json.loads(l) for l in fp.readlines()]\n",
    "        return metadata_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e318efb2-9afa-4414-b37f-71738d73d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metadata_dicts(\"data/llama2_metadata_dicts.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4edce99f-8a96-4539-95e7-62aeeabb2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dicts = load_metadata_dicts(\"data/llama2_metadata_dicts.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f18d2109-5fcb-4fd5-b147-23897fed8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all nodes consists of source nodes, along with metadata\n",
    "all_nodes = base_nodes\n",
    "for idx, d in enumerate(metadata_dicts):\n",
    "    inode_q = IndexNode(\n",
    "        text=d[\"questions_this_excerpt_can_answer\"], index_id=base_nodes[idx].node_id\n",
    "    )\n",
    "    inode_s = IndexNode(text=d[\"section_summary\"], index_id=base_nodes[idx].node_id)\n",
    "    all_nodes.extend([inode_q, inode_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f90ada6-0969-40cc-a4ec-3579b4900cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in all_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22abc768-83d5-41d0-84f0-533899c76894",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load index into vector index\n",
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "\n",
    "vector_index_metadata = VectorStoreIndex(all_nodes, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d53938a-1322-41b1-ad11-169b13b9805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_metadata = vector_index_metadata.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37ae791f-c183-4ad4-9a3a-253288ded5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_metadata = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_metadata},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cd85685-19eb-44cc-ad27-1d163eaddad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: node-22\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id node-22: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-22<br>**Similarity:** 0.8586394695721855<br>**Text:** We observe that models\n",
       "trained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\n",
       "safety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\n",
       "be applied before deployment of base Llama 2 models.\n",
       "22\n",
       "\n",
       "TruthfulQA ↑ToxiGen ↓\n",
       "MPT7B 29.13 22.32\n",
       "30B 35.25 22.61\n",
       "Falcon7B 25.95 14.53\n",
       "40B 40.39 23.44\n",
       "Llama 17B 27.42 23.00\n",
       "13B 41.74 23.08\n",
       "33B 44.19 22.57\n",
       "65B 48.71 21.77\n",
       "Llama 27B 33.29 21.25\n",
       "13B 41.86 26.10\n",
       "34B 43.45 21.19\n",
       "70B 50.18 24.60\n",
       "Table 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\n",
       "percentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\n",
       "present the percentage of toxic generations (the smaller, the better).\n",
       "Benchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\n",
       "patternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\n",
       "onpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\n",
       "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
       "in which a system may be deployed. For this, it may be necessary to test beyond the groups available in\n",
       "theBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\n",
       "continuing research that will amplify their potential for positive impact on these important social issues.\n",
       "4.2 Safety Fine-Tuning\n",
       "In this section, we describe our approach to safety fine-tuning, including safety categories, annotation\n",
       "guidelines,andthetechniquesweusetomitigatesafetyrisks. Weemployaprocesssimilartothegeneral\n",
       "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\n",
       "Specifically, we use the following techniques in safety fine-tuning:\n",
       "1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\n",
       "tions that are then included in...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever_metadata.retrieve(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5285854a-69a6-4bc4-a2a5-1004cc790a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_metadata = RetrieverQueryEngine.from_args(\n",
    "    retriever_metadata, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e0ada5c-9a83-4517-bbb7-899d4415d68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: node-22\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id node-22: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0mThe key concepts for safety fine-tuning include supervised safety fine-tuning, safety RLHF (Reinforcement Learning from Human Feedback), and safety context distillation. \n",
      "\n",
      "Supervised safety fine-tuning involves gathering adversarial prompts and safe demonstrations to train the model to align with safety guidelines even before RLHF. This helps establish a foundation for high-quality human preference data annotation.\n",
      "\n",
      "Safety RLHF integrates safety into the general RLHF pipeline. This includes training a safety-specific reward model and gathering more challenging adversarial prompts for rejection sampling style fine-tuning and PPO (Proximal Policy Optimization) optimization.\n",
      "\n",
      "Safety context distillation refines the RLHF pipeline by generating safer model responses through prefixing a prompt with a safety preprompt, such as \"You are a safe and responsible assistant.\" The model is then fine-tuned on the safer responses without the preprompt, effectively distilling the safety preprompt (context) into the model. A targeted approach is used to allow the safety reward model to choose whether to use context distillation for each sample.\n",
      "\n",
      "These concepts are employed to mitigate safety risks and ensure that the fine-tuned models align with safety guidelines.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_metadata.query(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973bdca-d179-47d6-bd96-2631b36e1d94",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We evaluate how well our recursive retrieval + node reference methods work. We evaluate both chunk references as well as metadata references. We use embedding similarity lookup to retrieve the reference nodes.\n",
    "\n",
    "We compare both methods against a baseline retriever where we fetch the raw nodes directly.\n",
    "\n",
    "In terms of metrics, we evaluate using both hit-rate and MRR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a30b7-2eb2-4eae-b0b9-1d4ec26ac915",
   "metadata": {},
   "source": [
    "### Dataset Generation\n",
    "\n",
    "We first generate a dataset of questions from the set of text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fe8ae8a-a2b2-4515-bcff-1145e14ede3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eef1b43d-996b-4b0a-becb-1cec08d9f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [03:27<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = generate_question_context_pairs(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3e2507-9157-48a5-909b-18eeb9ec01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.save_json(\"data/llama2_eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "611f07af-2006-4158-8dc6-59d11a269c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "eval_dataset = EmbeddingQAFinetuneDataset.from_json(\"data/llama2_eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4782a6-f3da-453f-93be-7683ed15b508",
   "metadata": {},
   "source": [
    "### Compare Results\n",
    "\n",
    "We run evaluations on each of the retrievers to measure hit rate and MRR.\n",
    "\n",
    "We find that retrievers with node references (either chunk or metadata) tend to perform better than retrieving the raw chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87798866-11bc-4f7f-b8aa-0a023309492f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index.evaluation import RetrieverEvaluator, get_retrieval_results_df\n",
    "\n",
    "# set vector retriever similarity top k to higher\n",
    "top_k = 10\n",
    "\n",
    "\n",
    "def display_results(names, results_arr):\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "\n",
    "    hit_rates = []\n",
    "    mrrs = []\n",
    "    for name, eval_results in zip(names, results_arr):\n",
    "        metric_dicts = []\n",
    "        for eval_result in eval_results:\n",
    "            metric_dict = eval_result.metric_vals_dict\n",
    "            metric_dicts.append(metric_dict)\n",
    "        results_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "        hit_rate = results_df[\"hit_rate\"].mean()\n",
    "        mrr = results_df[\"mrr\"].mean()\n",
    "        hit_rates.append(hit_rate)\n",
    "        mrrs.append(mrr)\n",
    "\n",
    "    final_df = pd.DataFrame({\"retrievers\": names, \"hit_rate\": hit_rates, \"mrr\": mrrs})\n",
    "    display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d142c6-0374-43ec-af31-e02d246bd815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=top_k)\n",
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=retriever_chunk\n",
    ")\n",
    "# try it out on an entire dataset\n",
    "results_chunk = await retriever_evaluator.aevaluate_dataset(\n",
    "    eval_dataset, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae448fe7-3a66-45a6-8e8e-6ed3950e61b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vector_retriever_metadata = vector_index_metadata.as_retriever(similarity_top_k=top_k)\n",
    "retriever_metadata = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_metadata},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=retriever_metadata\n",
    ")\n",
    "# try it out on an entire dataset\n",
    "results_metadata = await retriever_evaluator.aevaluate_dataset(\n",
    "    eval_dataset, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d3fc029-7ccc-4ec4-b391-b7b86744b5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                   | 0/167 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async embedding not available, falling back to sync method.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 167/167 [00:03<00:00, 49.50it/s]\n"
     ]
    }
   ],
   "source": [
    "base_retriever = base_index.as_retriever(similarity_top_k=10)\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=base_retriever\n",
    ")\n",
    "# try it out on an entire dataset\n",
    "results_base = await retriever_evaluator.aevaluate_dataset(\n",
    "    eval_dataset, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ef0cd73-b1ad-4ec6-931f-357d2ceebd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>0.796407</td>\n",
       "      <td>0.605097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retriever (Chunk References)</td>\n",
       "      <td>0.892216</td>\n",
       "      <td>0.739179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retriever (Metadata References)</td>\n",
       "      <td>0.916168</td>\n",
       "      <td>0.746906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        retrievers  hit_rate       mrr\n",
       "0                   Base Retriever  0.796407  0.605097\n",
       "1     Retriever (Chunk References)  0.892216  0.739179\n",
       "2  Retriever (Metadata References)  0.916168  0.746906"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_results_df = get_retrieval_results_df(\n",
    "    [\n",
    "        \"Base Retriever\",\n",
    "        \"Retriever (Chunk References)\",\n",
    "        \"Retriever (Metadata References)\",\n",
    "    ],\n",
    "    [results_base, results_chunk, results_metadata],\n",
    ")\n",
    "display(full_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de8db2-9e1e-4396-ba2e-821fd8223061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

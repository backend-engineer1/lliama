{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18e20fbc-056b-44ac-b1fc-2d34b8e99bcc",
   "metadata": {},
   "source": [
    "\n",
    "# Chat Engine - Condense Question Mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b99eea02-429c-40e4-99be-b82a89c8d070",
   "metadata": {},
   "source": [
    "Condense question is a simple chat mode built on top of a query engine over your data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34d34fcc-e247-4d55-ab16-c3d633e2385a",
   "metadata": {
    "tags": []
   },
   "source": [
    "For each chat interaction:\n",
    "* first generate a standalone question from conversation context and last message, then \n",
    "* query the query engine with the condensed question for a response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1c3cbc6-98a8-4e0e-98eb-3c7fa09ba79f",
   "metadata": {},
   "source": [
    "This approach is simple, and works for questions directly related to the knowledge base. \n",
    "Since it *always* queries the knowledge base, it can have difficulty answering meta questions like \"what did I ask you before?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b314f279-bf7f-4e67-9f66-ebf783f08d38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get started in 5 lines of code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1778820a-4c58-4b2f-8b1a-3d6f1f49995d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Load data and build index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ac125a-79df-452d-9f58-ac4f30997acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "data = SimpleDirectoryReader(input_dir=\"../data/paul_graham/\").load_data()\n",
    "index = VectorStoreIndex.from_documents(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e58d7ad9-d246-477e-acac-894ad5402f24",
   "metadata": {
    "tags": []
   },
   "source": [
    "Configure chat engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "164ef191-f86a-4ce1-aa9d-64d61f29dd45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine(chat_mode=\"condense_question\", verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63a4259d-89b5-49f8-b158-9eba5353d6f5",
   "metadata": {},
   "source": [
    "Chat with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825b5bb3-37ff-4886-be2c-264584ca9eab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: What was the next step in Paul Graham's career after his involvement with Y Combinator?\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"What did Paul Graham do after YC?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8fa4310-4dc5-4787-a073-755d2e0b4887",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paul Graham's next step in his career after his involvement with Y Combinator was to take up painting. He spent most of the rest of 2014 painting and then in March 2015 he started working on Lisp again.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67021e64-8665-4338-9fb4-c0f1d6361092",
   "metadata": {},
   "source": [
    "Ask a follow up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6181319-5d76-48c4-a5d4-23c6e9bc5ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: What did Paul Graham do after he started working on Lisp again in March 2015?\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"What about after that?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95045f5b-7964-4872-bc91-809d9debf1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paul Graham spent the rest of 2015 writing essays and working on his new dialect of Lisp, which he called Arc. He also looked for an apartment to buy and started planning a second still life painting from the same objects.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72cc02dd-90b7-4d63-bdb2-e4c4666f87ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: What did Paul Graham do after he started working on Lisp again in March 2015?\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"Can you tell me more?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f8efbb-fcb0-4c58-b92b-d2264a7e7103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paul Graham spent the rest of 2015 writing essays and working on his new dialect of Lisp, which he called Arc. He also looked for an apartment to buy and started planning for a second still life painting.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2c68de8-af58-4f7e-8759-19fc072873fd",
   "metadata": {},
   "source": [
    "Reset conversation state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d13cf082-1a91-43c5-8bad-76fa45be96f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "627de435-d195-4dad-b314-a68e731979a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: What happens after the current situation?\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"What about after that?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ef9e31-3cdb-4129-92f7-e61be201ea36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After the current situation, the narrator resumes painting and experimenting with a new kind of still life. He also resumes his old life in New York, now that he is rich. He is able to take taxis and eat in restaurants, which is exciting for a while. He also starts to make connections with other people who are trying to paint in New York.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a65ad1a2",
   "metadata": {},
   "source": [
    "## Streaming Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad272dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    ")\n",
    "\n",
    "data = SimpleDirectoryReader(input_dir=\"../data/paul_graham/\").load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(data, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22605caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine(chat_mode=\"condense_question\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "250abd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: What did Paul Graham do after leaving YC?\n",
      "After leaving YC, Paul Graham started painting and focused on improving his skills in that area. He then started writing essays again and began working on Lisp."
     ]
    }
   ],
   "source": [
    "response = chat_engine.stream_chat(\"What did Paul Graham do after YC?\")\n",
    "for token in response.response_gen:\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dbf8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

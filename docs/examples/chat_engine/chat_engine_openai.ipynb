{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3e1610-942d-458e-8379-ebb1fe88ac2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chat Engine - OpenAI Agent Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3cb595-1bd4-446e-93ba-6e3cfc1d4a29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get started in 5 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f4d3a-b84c-409d-b371-85c33ab7b68f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Load data and build index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a258574-a4d1-42cc-9f1a-bc6f5d4c6a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# Necessary to use the latest OpenAI models that support function calling API\n",
    "service_context = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-3.5-turbo-0613\"))\n",
    "data = SimpleDirectoryReader(input_dir=\"../data/paul_graham/\").load_data()\n",
    "index = VectorStoreIndex.from_documents(data, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0dc626-c877-422f-913a-afd3d3c8cdc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Configure chat engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37717d64-851d-46c2-b64c-2f5efaaa37f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine(chat_mode=\"openai\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b86747-22ca-4626-9df7-ff123ac57883",
   "metadata": {
    "tags": []
   },
   "source": [
    "Chat with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f09367b-375a-47d3-b0b4-0753b52d834d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"Hi\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4b6686-21cd-4974-b767-4ebad4cefb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: query_engine_tool with args: {\n",
      "  \"input\": \"Who did Paul Graham hand over YC to?\"\n",
      "}\n",
      "Got output: Paul Graham handed over YC to Sam Altman.\n",
      "========================\n",
      "Paul Graham handed over Y Combinator (YC) to Sam Altman.\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\n",
    "    \"Use the tool to answer: Who did Paul Graham hand over YC to?\"\n",
    ")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

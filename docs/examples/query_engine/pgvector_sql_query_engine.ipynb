{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1fa9b8e-8aa1-4591-9ed1-0f0931160146",
   "metadata": {},
   "source": [
    "# [Beta] Text-to-SQL with PGVector\n",
    "\n",
    "This notebook demo shows how to perform text-to-SQL with pgvector. This allows us to jointly do both semantic search and structured querying, *all* within SQL!\n",
    "\n",
    "This hypothetically enables more expressive queries than semantic search + metadata filters.\n",
    "\n",
    "**NOTE**: This is a beta feature, interfaces might change. But in the meantime hope you find it useful! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00afde6-9fa6-4001-ae2b-ac56cb858ceb",
   "metadata": {},
   "source": [
    "## Setup Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0a1a2-f66e-4c81-9435-771ea50652fa",
   "metadata": {},
   "source": [
    "### Load Documents\n",
    "\n",
    "Load in the Lyft 2021 10k document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e32d8-349f-4477-992f-549cfd6a4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_hub.file.pdf.base import PDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd432b9-7a6a-4734-a8d9-3d18c12c64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PDFReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1f7c8-49bc-4349-815e-97b075bab00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = reader.load_data(\"../data/10k/lyft_2021.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da729bfb-5aa7-4c12-88ae-860c0a5ec1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults()\n",
    "nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdaebd8-e067-41ec-90d8-96825b5a5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodes[8].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c7593-cef8-487e-bafb-d9322aa79e87",
   "metadata": {},
   "source": [
    "### Insert data into Postgres + PGVector\n",
    "\n",
    "Make sure you have all the necessary dependencies installed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18cfa54-9300-4d83-858e-8a85f79113dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary pgvector asyncpg \"sqlalchemy[asyncio]\" greenlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc47918-fb83-4ba7-ae2d-fbe202fe769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.sqlalchemy import Vector\n",
    "from sqlalchemy import insert, create_engine, String, text, Integer\n",
    "from sqlalchemy.orm import declarative_base, mapped_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b5c99-c498-4de2-9097-ab81165d2c20",
   "metadata": {},
   "source": [
    "#### Establish Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d1c27-293c-4b46-9354-67d861e89f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql+psycopg2://localhost/postgres\")\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c526c0-697f-405b-bc34-919d1771c09d",
   "metadata": {},
   "source": [
    "#### Define Table Schema \n",
    "\n",
    "Define as Python class. Note we store the page_label, embedding, and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09854077-239c-4ee6-a760-aeb133296c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "class SECTextChunk(Base):\n",
    "    __tablename__ = \"sec_text_chunk\"\n",
    "\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    page_label = mapped_column(Integer)\n",
    "    file_name = mapped_column(String)\n",
    "    text = mapped_column(String)\n",
    "    embedding = mapped_column(Vector(384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e34e55-5f8c-4942-8acb-7bee2a4ffabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3da71a-6e19-4caf-bef8-5e5228ad5477",
   "metadata": {},
   "source": [
    "#### Generate embedding for each Node with a sentence_transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7fc99-fa66-4642-b522-439496adf98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings for each row\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\")\n",
    "\n",
    "for node in nodes:\n",
    "    text_embedding = embed_model.get_text_embedding(node.get_content())\n",
    "    node.embedding = text_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ec8a7-8a29-4eb1-9a05-ae43ef07944d",
   "metadata": {},
   "source": [
    "#### Insert into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557e2aa-2de6-4f70-a6f5-2283b2545523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert into database\n",
    "for node in nodes:\n",
    "    row_dict = {\n",
    "        \"text\": node.get_content(),\n",
    "        \"embedding\": node.embedding,\n",
    "        **node.metadata,\n",
    "    }\n",
    "    stmt = insert(SECTextChunk).values(**row_dict)\n",
    "    with engine.connect() as connection:\n",
    "        cursor = connection.execute(stmt)\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4957e-2aeb-4851-9d88-779f3edcd665",
   "metadata": {},
   "source": [
    "## Define PGVectorSQLQueryEngine\n",
    "\n",
    "Now that we've loaded the data into the database, we're ready to setup our query engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49474918-5f16-4ff3-a54e-21a123ddebd7",
   "metadata": {},
   "source": [
    "### Define Prompt\n",
    "\n",
    "We create a modified version of our default text-to-SQL prompt to inject awareness of the pgvector syntax.\n",
    "We also prompt it with some few-shot examples of how to use the syntax (<-->). \n",
    "\n",
    "**NOTE**: This is included by default in the `PGVectorSQLQueryEngine`, we included it here mostly for visibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21beb67b-5538-4cb0-b6f8-d093cfaee9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.prompts import PromptTemplate\n",
    "\n",
    "text_to_sql_tmpl = \"\"\"\\\n",
    "Given an input question, first create a syntactically correct {dialect} \\\n",
    "query to run, then look at the results of the query and return the answer. \\\n",
    "You can order the results by a relevant column to return the most \\\n",
    "interesting examples in the database.\n",
    "\n",
    "Pay attention to use only the column names that you can see in the schema \\\n",
    "description. Be careful to not query for columns that do not exist. \\\n",
    "Pay attention to which column is in which table. Also, qualify column names \\\n",
    "with the table name when needed. \n",
    "\n",
    "IMPORTANT NOTE: you can use specialized pgvector syntax (`<-->`) to do nearest \\\n",
    "neighbors/semantic search to a given vector from an embeddings column in the table. \\\n",
    "The embeddings value for a given row typically represents the semantic meaning of that row. \\\n",
    "The vector represents an embedding representation \\\n",
    "of the question, given below. Do NOT fill in the vector values directly, but rather specify a \\\n",
    "`[query_vector]` placeholder. For instance, some select statement examples below \\\n",
    "(the name of the embeddings column is `embedding`):\n",
    "SELECT * FROM items ORDER BY embedding <-> '[query_vector]' LIMIT 5;\n",
    "SELECT * FROM items WHERE id != 1 ORDER BY embedding <-> (SELECT embedding FROM items WHERE id = 1) LIMIT 5;\n",
    "SELECT * FROM items WHERE embedding <-> '[query_vector]' < 5;\n",
    "\n",
    "You are required to use the following format, \\\n",
    "each taking one line:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use tables listed below.\n",
    "{schema}\n",
    "\n",
    "\n",
    "Question: {query_str}\n",
    "SQLQuery: \\\n",
    "\"\"\"\n",
    "text_to_sql_prompt = PromptTemplate(text_to_sql_tmpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d0f5c2-ece7-4152-80fc-52d6f0fe6657",
   "metadata": {},
   "source": [
    "### Setup LLM, Embedding Model, and Misc.\n",
    "\n",
    "Besides LLM and embedding model, note we also add annotations on the table itself. This better helps the LLM \n",
    "understand the column schema (e.g. by telling it what the embedding column represents) to better do \n",
    "either tabular querying or semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af7f7c-b587-4a2d-9f2e-045c392b56fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerryliu/Programming/gpt_index/llama_index/utilities/sql_wrapper.py:118: SAWarning: Did not recognize type 'vector' of column 'embedding'\n",
      "  self._metadata.reflect(\n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext, SQLDatabase\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.query_engine import PGVectorSQLQueryEngine\n",
    "\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"sec_text_chunk\"])\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\n",
    "\n",
    "table_desc = \"\"\"\\\n",
    "This table represents text chunks from an SEC filing. Each row contains the following columns:\n",
    "\n",
    "id: id of row\n",
    "page_label: page number \n",
    "file_name: top-level file name\n",
    "text: all text chunk is here\n",
    "embedding: the embeddings representing the text chunk\n",
    "\n",
    "For most queries you should perform semantic search against the `embedding` column values, since \\\n",
    "that encodes the meaning of the text.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "context_query_kwargs = {\"sec_text_chunk\": table_desc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353143c5-10e7-482b-8deb-ccb078993116",
   "metadata": {},
   "source": [
    "### Define Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323a880-acf8-4d92-9b3e-b6d21a5c10f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = PGVectorSQLQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    text_to_sql_prompt=text_to_sql_prompt,\n",
    "    service_context=service_context,\n",
    "    context_query_kwargs=context_query_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c8529-1c6e-4df5-9060-fd472d00ff16",
   "metadata": {},
   "source": [
    "## Run Some Queries\n",
    "\n",
    "Now we're ready to run some queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd9ee7-a029-4002-87df-a6fe88a0d2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerryliu/Programming/gpt_index/llama_index/utilities/sql_wrapper.py:166: SAWarning: Did not recognize type 'vector' of column 'embedding'\n",
      "  for column in self._inspector.get_columns(table_name):\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Can you tell me about the risk factors described in page 6?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c809ef-8f6a-47e7-94c1-faa015ab2405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text on page 6 discusses the impact of the COVID-19 pandemic on the business. It mentions that the pandemic has affected communities in the United States, Canada, and globally. It has also led to significant disruptions in the business, including a decrease in the number of riders and drivers, reduced hours of operation, and increased costs. The text also discusses the company's transportation network, which offers riders seamless, personalized, and on-demand access to a variety of mobility options.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c709e6e-3b1d-4381-9826-d7c464605db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.metadata[\"sql_query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4883c-86f6-4a2e-a536-ef23c828681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"Tell me more about Lyft's real estate operating leases\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e01b83-bf19-4f08-86b6-e85d75240bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyft's lease arrangements include vehicle rental agreements that are accounted for as operating leases. These leases do not meet any specific criteria that would categorize them otherwise. The company's leasehold improvements are amortized on a straight-line basis over the shorter of the term of the lease or the useful life of the assets.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5d62b-e977-41dc-8839-105382960c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM sec_text_chunk WHERE text LIKE '%Lyft%' AND text LIKE '%real estate%' AND text LIKE '%operating leases%' ORDER BY embedding <-> '[-0.06691089272499084, -0.41431307792663574, 0.2750679850578308, 0.19374045729637146, 0.08942480385303497, -0.16577985882759094, 0.399348646402359, 0.3634052\n"
     ]
    }
   ],
   "source": [
    "print(response.metadata[\"sql_query\"][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d148595-dc81-42e5-b49f-5b753b35fbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(157, 93, 'lyft_2021.pdf', \"Leases that do not meet any of the above criteria are accounted for as operating leases.Lessor\\nThe\\n Company's lease arrangements include vehicle re ... (4356 characters truncated) ...  realized. Leasehold improvements are amortized on a straight-line basis over the shorter of the term of the lease, or the useful life of the assets.\", '[0.16887704,-0.22762142,0.040292107,0.2951868,0.034039058,-0.092776,0.23275128,0.12367551,0.17209437,-0.08910224,0.30044347,0.1590553,0.21984532,-0.1 ... (4111 characters truncated) ... 0.24707487,0.10685501,0.42726353,-0.16156487,-0.2705381,-0.15468368,0.100748956,-0.19910589,-0.06634029,-0.7986131,-0.14139938,0.55980897,0.31352338]')]\n"
     ]
    }
   ],
   "source": [
    "# looked at returned result\n",
    "print(response.metadata[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eed23b-859b-48bf-b2db-0d29b105d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structured query\n",
    "response = query_engine.query(\n",
    "    \"Tell me about the max page number in this table\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67378df7-de00-4236-b7c8-4881b42ce818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum page number in this table is 238.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae4a799-e65e-403c-9cdf-33c482515d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT MAX(page_label) FROM sec_text_chunk;\n"
     ]
    }
   ],
   "source": [
    "print(response.metadata[\"sql_query\"][:300])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07531d9-7473-480d-bee6-c1ee4cbc207c",
   "metadata": {},
   "source": [
    "# Extracting Metadata for Better Document Indexing and Understanding\n",
    "\n",
    "In many cases, especially with long documents, a chunk of text may lack the context necessary to disambiguate the chunk from other similar chunks of text. One method of addressing this is manually labelling each chunk in our dataset or knowledge base. However, this can be labour intensive and time consuming for a large number or continually updated set of documents.\n",
    "\n",
    "To combat this, we use LLMs to extract certain contextual information relevant to the document to better help the retrieval and language models disambiguate similar-looking passages.\n",
    "\n",
    "We do this through our brand-new `MetadataExtractor` modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c807cc-1334-4f92-8a9e-9ccd702f3578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0adb8e4a-6728-4073-8256-8b3be4ab1e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import ListIndex, LLMPredictor\n",
    "from langchain import OpenAI\n",
    "from llama_index import download_loader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.schema import MetadataMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0231dff-7443-46bf-9b9d-759198d3408e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_predictor = LLMPredictor(\n",
    "    llm=OpenAI(temperature=0, model_name=\"text-davinci-003\", max_tokens=512)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2cf90-f295-4a3d-a47c-4b2b1dd2d7c5",
   "metadata": {},
   "source": [
    "We create a node parser that extracts the document title and hypothetical question embeddings relevant to the document chunk.\n",
    "\n",
    "We also show how to instantiate the `SummaryExtractor` and `KeywordExtractor`, as well as how to create your own custom extractor \n",
    "based on the `MetadataFeatureExtractor` base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bda151d-6fb8-427e-82fc-0f3bb469d705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.node_parser.extractors import (\n",
    "    MetadataExtractor,\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    "    KeywordExtractor,\n",
    "    MetadataFeatureExtractor,\n",
    ")\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(separator=\" \", chunk_size=512, chunk_overlap=128)\n",
    "\n",
    "\n",
    "class CustomExtractor(MetadataFeatureExtractor):\n",
    "    def extract(self, nodes):\n",
    "        metadata_list = [\n",
    "            {\n",
    "                \"custom\": node.metadata[\"document_title\"]\n",
    "                + \"\\n\"\n",
    "                + node.metadata[\"excerpt_keywords\"]\n",
    "            }\n",
    "            for node in nodes\n",
    "        ]\n",
    "        return metadata_list\n",
    "\n",
    "\n",
    "metadata_extractor = MetadataExtractor(\n",
    "    extractors=[\n",
    "        TitleExtractor(nodes=5),\n",
    "        QuestionsAnsweredExtractor(questions=3),\n",
    "        # SummaryExtractor(summaries=[\"prev\", \"self\"]),\n",
    "        # KeywordExtractor(keywords=10),\n",
    "        # CustomExtractor()\n",
    "    ],\n",
    ")\n",
    "\n",
    "node_parser = SimpleNodeParser(\n",
    "    text_splitter=text_splitter,\n",
    "    metadata_extractor=metadata_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c72c45a9-dcad-4925-b2f7-d25fe5d80c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, DocumentSummaryIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e54937-e9e7-48ed-8600-72cd2f3c529b",
   "metadata": {},
   "source": [
    "We first load the 10k annual SEC report for Uber and Lyft for the years 2019 and 2020 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5ef50-82ef-4936-bbc2-c022f67007a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!wget -O \"data/10k-132.pdf\" \"https://www.dropbox.com/scl/fi/6dlqdk6e2k1mjhi8dee5j/uber.pdf?rlkey=2jyoe49bg2vwdlz30l76czq6g&dl=1\"\n",
    "!wget -O \"data/10k-vFinal.pdf\" \"https://www.dropbox.com/scl/fi/qn7g3vrk5mqb18ko4e5in/lyft.pdf?rlkey=j6jxtjwo8zbstdo4wz3ns8zoj&dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a46bf6-9539-4ac2-ad97-eb909992b94d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note the uninformative document file name, which may be a common scenario in a production setting\n",
    "uber_docs = SimpleDirectoryReader(input_files=[\"data/10k-132.pdf\"]).load_data()\n",
    "uber_front_pages = uber_docs[0:3]\n",
    "uber_content = uber_docs[63:69]\n",
    "uber_docs = uber_front_pages + uber_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269f8ecc-489d-435f-9d81-a9c64fd4d400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uber_nodes = node_parser.get_nodes_from_documents(uber_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da4d824-d518-4d37-8322-a35adac05157",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_label': '2',\n",
       " 'file_name': '10k-132.pdf',\n",
       " 'document_title': 'Uber Technologies, Inc. 2019 Annual Report: Revolutionizing Mobility and Logistics Across 69 Countries and 111 Million MAPCs with $65 Billion in Gross Bookings',\n",
       " 'questions_this_excerpt_can_answer': '\\n\\n1. How many countries does Uber Technologies, Inc. operate in?\\n2. What is the total number of MAPCs served by Uber Technologies, Inc.?\\n3. How much gross bookings did Uber Technologies, Inc. generate in 2019?'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_nodes[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e70bfb-6c02-401b-be91-3827f358b22c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note the uninformative document file name, which may be a common scenario in a production setting\n",
    "lyft_docs = SimpleDirectoryReader(input_files=[\"data/10k-vFinal.pdf\"]).load_data()\n",
    "lyft_front_pages = lyft_docs[0:3]\n",
    "lyft_content = lyft_docs[68:73]\n",
    "lyft_docs = lyft_front_pages + lyft_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3720b40-c50c-4185-aaf4-289ff8ab057e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lyft_nodes = node_parser.get_nodes_from_documents(lyft_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98740f96-afdd-45ff-bcc0-2c50965a7349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_label': '2',\n",
       " 'file_name': '10k-vFinal.pdf',\n",
       " 'document_title': \"Lyft, Inc. 2021 Annual Meeting of Stockholders: Filing and Attestation of Management's Assessment Report, Filer Status, Internal Control Assessment, Shell Company Status, Market Value of Common Stock, and Analysis of Historical Financial Performance.\",\n",
       " 'questions_this_excerpt_can_answer': '\\n\\n1. What is the status of the registrant as an accelerated filer?\\n2. Has the registrant filed a report on and attestation to its management’s assessment of the effectiveness of its internal control over financial reporting?\\n3. What is the total number of shares of Class A and Class B common stock outstanding as of February 22, 2021?'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyft_nodes[2].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd5805f-c459-40ae-a21c-5fa0de750a60",
   "metadata": {},
   "source": [
    "Since we are asking fairly sophisticated questions, we utilize a subquestion query engine for all QnA pipelines below, and prompt it to pay more attention to the relevance of the retrieved sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "302bb085-86cc-4b76-a452-67bc826b292d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.question_gen.llm_generators import LLMQuestionGenerator\n",
    "from llama_index.question_gen.prompts import DEFAULT_SUB_QUESTION_PROMPT_TMPL\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor, node_parser=node_parser\n",
    ")\n",
    "question_gen = LLMQuestionGenerator.from_defaults(\n",
    "    service_context=service_context,\n",
    "    prompt_template_str=\"\"\"\n",
    "        Follow the example, but instead of giving a question, always prefix the question \n",
    "        with: 'By first identifying and quoting the most relevant sources, '. \n",
    "        \"\"\"\n",
    "    + DEFAULT_SUB_QUESTION_PROMPT_TMPL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd959f-80ac-4d10-9246-d27cc6c1096a",
   "metadata": {},
   "source": [
    "## Querying an Index With No Extra Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37dd8992-3716-44da-9309-154fb5946e98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM sees:\n",
      " [Excerpt from document]\n",
      "page_label: 65\n",
      "file_name: 10k-132.pdf\n",
      "Excerpt:\n",
      "-----\n",
      "See the section titled “Reconciliations of Non-GAAP Financial Measures” for our definition and a \n",
      "reconciliation of net income (loss) attributable to  Uber Technologies, Inc. to Adjusted EBITDA. \n",
      "            \n",
      "  Year Ended December 31,   2017 to 2018   2018 to 2019   \n",
      "(In millions, exce pt percenta ges)  2017   2018   2019   % Chan ge  % Chan ge  \n",
      "Adjusted EBITDA ................................  $ (2,642) $ (1,847) $ (2,725)  30%  (48)%\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "nodes_no_metadata = deepcopy(uber_nodes) + deepcopy(lyft_nodes)\n",
    "for node in nodes_no_metadata:\n",
    "    node.metadata = {\n",
    "        k: node.metadata[k] for k in node.metadata if k in [\"page_label\", \"file_name\"]\n",
    "    }\n",
    "print(\"LLM sees:\\n\", (nodes_no_metadata)[9].get_content(metadata_mode=MetadataMode.LLM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8ff619d-67ed-4263-bfc7-2a7a1b7320e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.vector_stores import FaissVectorStore\n",
    "from llama_index.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "028a65d7-8065-4798-acec-1c3486633e14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_no_metadata = VectorStoreIndex(nodes=nodes_no_metadata)\n",
    "engine_no_metadata = index_no_metadata.as_query_engine(similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73ea9e05-ff5a-49b6-8e52-139d156cde47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_engine_no_metadata = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=[\n",
    "        QueryEngineTool(\n",
    "            query_engine=engine_no_metadata,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"sec_filing_documents\",\n",
    "                description=\"financial information on companies\",\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    question_gen=question_gen,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd5a3e51-e252-4e24-bc2b-fbc32ce078dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 sub questions.\n",
      "\u001b[36;1m\u001b[1;3m[sec_filing_documents] Q: By first identifying and quoting the most relevant sources, what was the cost due to research and development for Uber in 2019 in millions of USD?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[sec_filing_documents] Q: By first identifying and quoting the most relevant sources, what was the cost due to sales and marketing for Uber in 2019 in millions of USD?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[sec_filing_documents] Q: By first identifying and quoting the most relevant sources, what was the cost due to research and development for Lyft in 2019 in millions of USD?\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m[sec_filing_documents] Q: By first identifying and quoting the most relevant sources, what was the cost due to sales and marketing for Lyft in 2019 in millions of USD?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[sec_filing_documents] A: \n",
      "\n",
      "According to the excerpt from page_label: 69 and file_name: 10k-132.pdf, the cost due to research and development for Lyft in 2019 was 15% of total revenue, or $1.5 billion in millions of USD.\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[sec_filing_documents] A: \n",
      "\n",
      "According to the excerpt from page_label 66 of the 10k-132.pdf document, the cost due to sales and marketing for Uber in 2019 was $397.8 million in thousands of USD, or $397,800,000 in millions of USD. This cost was primarily attributable to continued investments within Uber's non-Rides offerings and an increase in corporate overhead as the business grows.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[sec_filing_documents] A: \n",
      "\n",
      "According to the excerpt from page 69 of the document 10k-132.pdf, research and development expenses for Uber in 2019 were $909.1 million in thousands of USD, which equates to $909.1 million in millions of USD. This was 9% of the total costs and expenses for the year, and accounted for 34% of the total revenue.\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m[sec_filing_documents] A: \n",
      "\n",
      "According to the excerpt from page_label 72 of the 10k-vFinal.pdf document, the cost due to sales and marketing for Lyft in 2019 was $275.1 million in thousands of USD. This can be seen in the following excerpt: \n",
      "\n",
      "\"Sales and marketing $ 196,437 $ 194,184 $ 163,858 $ 180,951 $ 275,129 \n",
      "Year Ended December 31,2019 to 2020 \n",
      "% Change2018 to 2019 \n",
      "% Change\"\n",
      "\u001b[0mAnswer: \n",
      "{\n",
      "    \"Uber\": {\n",
      "        \"Research and Development\": 909.1,\n",
      "        \"Sales and Marketing\": 397.8\n",
      "    },\n",
      "    \"Lyft\": {\n",
      "        \"Research and Development\": 1.5,\n",
      "        \"Sales and Marketing\": 275.1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response_no_metadata = final_engine_no_metadata.query(\n",
    "    \"\"\"\n",
    "    What was the cost due to research and development v.s. sales and marketing for uber and lyft in 2019 in millions of USD?\n",
    "    Give your answer as a JSON.\n",
    "    \"\"\"\n",
    ")\n",
    "print(response_no_metadata.response)\n",
    "# Correct answer:\n",
    "# {\"Uber\": {\"Research and Development\": 4836, \"Sales and Marketing\": 4626},\n",
    "#  \"Lyft\": {\"Research and Development\": 1505.6, \"Sales and Marketing\": 814 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dafdad-c18c-4e0f-8a35-b691ca73e1f2",
   "metadata": {},
   "source": [
    "**RESULT**: As we can see, the QnA agent does not seem to know where to look for the right documents. As a result it gets only 1/4 of the subquestions right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878905f-c47d-46b2-9ad9-063538e717e1",
   "metadata": {},
   "source": [
    "## Querying an Index With Extracted Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97f00a18-e9e6-47db-bef5-cbf5bb5016be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM sees:\n",
      " [Excerpt from document]\n",
      "page_label: 65\n",
      "file_name: 10k-132.pdf\n",
      "document_title: Uber Technologies, Inc. 2019 Annual Report: Revolutionizing Mobility and Logistics Across 69 Countries and 111 Million MAPCs with $65 Billion in Gross Bookings\n",
      "questions_this_excerpt_can_answer: \n",
      "\n",
      "1. What is Uber Technologies, Inc.'s definition of Adjusted EBITDA?\n",
      "2. How much did Adjusted EBITDA change from 2017 to 2018?\n",
      "3. How much did Adjusted EBITDA change from 2018 to 2019?\n",
      "Excerpt:\n",
      "-----\n",
      "See the section titled “Reconciliations of Non-GAAP Financial Measures” for our definition and a \n",
      "reconciliation of net income (loss) attributable to  Uber Technologies, Inc. to Adjusted EBITDA. \n",
      "            \n",
      "  Year Ended December 31,   2017 to 2018   2018 to 2019   \n",
      "(In millions, exce pt percenta ges)  2017   2018   2019   % Chan ge  % Chan ge  \n",
      "Adjusted EBITDA ................................  $ (2,642) $ (1,847) $ (2,725)  30%  (48)%\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"LLM sees:\\n\",\n",
    "    (uber_nodes + lyft_nodes)[9].get_content(metadata_mode=MetadataMode.LLM),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7d255de-3034-4035-93bc-45d535ce1700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes=uber_nodes + lyft_nodes)\n",
    "engine = index.as_query_engine(similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe42516-a2ca-4986-9012-cb15682323f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=[\n",
    "        QueryEngineTool(\n",
    "            query_engine=engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"sec_filing_documents\",\n",
    "                description=\"financial information on companies.\",\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    question_gen=question_gen,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f48ac2d9-58e9-4b98-9bad-b8ce1eea7934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 sub questions.\n",
      "\u001b[36;1m\u001b[1;3m[sec_filing_documents] Q: By first identifying and quoting the most relevant sources, what was the cost due to research and development for Uber in 2019 in millions of USD?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[sec_filing_documents] Q: By first identifying and quoting the most relevant sources, what was the cost due to sales and marketing for Uber in 2019 in millions of USD?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[sec_filing_documents] Q: By first identifying and quoting the most relevant sources, what was the cost due to research and development for Lyft in 2019 in millions of USD?\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m[sec_filing_documents] Q: By first identifying and quoting the most relevant sources, what was the cost due to sales and marketing for Lyft in 2019 in millions of USD?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[sec_filing_documents] A: \n",
      "\n",
      "According to the excerpt from the document, Lyft spent $1,505 million on research and development in 2019. This was 34% of total costs and expenses for the year.\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[sec_filing_documents] A: \n",
      "\n",
      "According to the excerpt from page 69 of the Uber Technologies, Inc. 2019 Annual Report, the cost due to sales and marketing for Uber in 2019 was $4,626 million in USD. This cost was driven by investments in non-Rides offerings, corporate overhead, and Driver incentives.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[sec_filing_documents] A: \n",
      "\n",
      "According to the excerpt from page 69 of the document, Uber Technologies, Inc. spent $4.836 billion on research and development in 2019, which was driven by a 22% increase in MAPCs due to global expansion of their Eats product offerings combined with wider market adoption of their Rides product, and overall growth in their other offerings.\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m[sec_filing_documents] A: \n",
      "\n",
      "According to the excerpt from page 69 of the document titled \"Lyft, Inc. 2021 Annual Meeting of Stockholders: Filing and Attestation of Management's Assessment Report, Filer Status, Internal Control Assessment, Shell Company Status, Market Value of Common Stock, and Analysis of Historical Financial Performance,\" the cost due to sales and marketing for Lyft in 2019 was $814.122 million in USD. This can be found in the table under the heading \"2020 2019 2018 (in thousands)\" which states that \"Sales and marketing $416,331 $814,122 $803,751.\"\n",
      "\u001b[0mAnswer: \n",
      "{\n",
      "    \"Uber\": {\n",
      "        \"Research and Development\": 4.836,\n",
      "        \"Sales and Marketing\": 4.626\n",
      "    },\n",
      "    \"Lyft\": {\n",
      "        \"Research and Development\": 1.505,\n",
      "        \"Sales and Marketing\": 0.814\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = final_engine.query(\n",
    "    \"\"\"\n",
    "    What was the cost due to research and development v.s. sales and marketing for uber and lyft in 2019 in millions of USD?\n",
    "    Give your answer as a JSON.\n",
    "    \"\"\"\n",
    ")\n",
    "print(response.response)\n",
    "# Correct answer:\n",
    "# {\"Uber\": {\"Research and Development\": 4836, \"Sales and Marketing\": 4626},\n",
    "#  \"Lyft\": {\"Research and Development\": 1505.6, \"Sales and Marketing\": 814 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee6d91-84f4-4bde-89dc-d010f9aebc3e",
   "metadata": {},
   "source": [
    "**RESULT**: As we can see, the LLM answers the questions correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14826bae-4032-4886-87a8-50f9f28d7ace",
   "metadata": {},
   "source": [
    "### Challenges Identified in the Problem Domain\n",
    "\n",
    "In this example, we observed that the search quality as provided by vector embeddings was rather poor. This was likely due to highly dense financial documents that were likely not representative of the training set for the model.\n",
    "\n",
    "In order to improve the search quality, other methods of neural search that employ more keyword-based approaches may help, such as ColBERTv2/PLAID. In particular, this would help in matching on particular keywords to identify high-relevance chunks.\n",
    "\n",
    "Other valid steps may include utilizing models that are fine-tuned on financial datasets such as Bloomberg GPT.\n",
    "\n",
    "Finally, we can help to further enrich the metadata by providing more contextual information regarding the surrounding context that the chunk is located in.\n",
    "\n",
    "### Improvements to this Example\n",
    "Generally, this example can be improved further with more rigorous evaluation of both the metadata extraction accuracy, and the accuracy and recall of the QnA pipeline. Further, incorporating a larger set of documents as well as the full length documents, which may provide more confounding passages that are difficult to disambiguate, could further stresss test the system we have built and suggest further improvements. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_jon",
   "language": "python",
   "name": "llama_index_jon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

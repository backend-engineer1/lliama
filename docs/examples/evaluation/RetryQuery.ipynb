{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retry Query Engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to add your OpenAI API key or enable debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['OPENAI_API_KEY'] = \"INSERT OPENAI KEY\"\n",
    "\n",
    "# import logging\n",
    "# import sys\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we ingest the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.query_engine.retry_source_query_engine import RetrySourceQueryEngine\n",
    "from llama_index.readers.file.base import SimpleDirectoryReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('../data/paul_graham/').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query = \"What did the author do growing up?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will query with the default settings first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default query engine response: \n",
      "The author grew up writing essays, learning Italian, exploring Florence, painting people, working with computers, attending RISD, living in a rent-stabilized apartment, building an online store builder, editing Lisp expressions, publishing essays online, writing essays, painting still life, working on spam filters, cooking for groups, and buying a building in Cambridge.\n"
     ]
    }
   ],
   "source": [
    "# Default query engine\n",
    "default_query_engine = index.as_query_engine()\n",
    "response = default_query_engine.query(query)\n",
    "print(f\"Default query engine response: {response}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with retry, if the response does not pass the evaluator the query engine passed in will be rerun with the negative counterexample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query engine with retry response: \n",
      "The author grew up writing essays, learning Italian, exploring Florence, painting people, working with computers, attending RISD, living in a rent-controlled apartment, building an online store builder, editing code, launching software, publishing essays online, writing essays, painting still life, working on spam filters, cooking for groups, and buying a building in Cambridge.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.query_engine.retry_query_engine import (\n",
    "    RetryQueryEngine,\n",
    ")\n",
    "from llama_index.evaluation.base import QueryResponseEvaluator\n",
    "\n",
    "# Query engine with retry\n",
    "query_response_evaluator = QueryResponseEvaluator()\n",
    "retry_query_engine = RetryQueryEngine(index.as_query_engine(), query_response_evaluator)\n",
    "retry_response = retry_query_engine.query(query)\n",
    "print(f\"Query engine with retry response: {retry_response}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Source Retry modifies the query source nodes by filtering the existing source nodes for the query based on llm node evaluation.\n",
    "\n",
    "A better solution would be to re-retrieve based on filtering out the nodes that didn't pass evaluation.\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query engine with retry source response: \n",
      "The author grew up writing essays, learning Italian, exploring Florence, painting people, learning about computers, attending RISD, living in a rent-stabilized apartment, building an online store builder, editing Lisp expressions, publishing essays online, writing essays, painting still life, working on spam filters, cooking for groups, and buying a building in Cambridge.\n"
     ]
    }
   ],
   "source": [
    "retry_source_query_engine = RetrySourceQueryEngine(index.as_query_engine(), query_response_evaluator)\n",
    "retry_source_response = retry_source_query_engine.query(query)\n",
    "print(f\"Query engine with retry source response: {retry_source_response}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module tries to use guidelines to direct the evaluator's behavior. You can customize your own guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guideline eval evaluation result: The response is too long and should be summarized. It should also include specific numbers or statistics when possible.\n",
      "Transformed query: Here is a previous bad answer.\n",
      "\n",
      "The author grew up writing essays, learning Italian, exploring Florence, painting people, working with computers, attending RISD, living in a rent-stabilized apartment, building an online store builder, editing Lisp expressions, publishing essays online, writing essays, painting still life, working on spam filters, cooking for groups, and buying a building in Cambridge.\n",
      "Here is some feedback from the evaluator about the response given.\n",
      "The response is too long and should be summarized. It should also include specific numbers or statistics when possible.\n",
      "Now answer the question.\n",
      "\n",
      "What experiences did the author have growing up?\n",
      "Query engine with retry guideline response: \n",
      "The author had a wide range of experiences growing up. They wrote essays, explored Florence, painted people, worked with computers, attended RISD, lived in a rent-stabilized apartment, built an online store builder, edited Lisp expressions, published essays online, painted still life, worked on spam filters, cooked for groups, and bought a building in Cambridge. They also learned Italian and had a deep understanding of the web and its implications, which enabled them to recognize the potential of publishing essays online and take advantage of the new opportunities it presented.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.evaluation.guideline_eval import GuidelineEvaluator, DEFAULT_GUIDELINES\n",
    "from llama_index.response.schema import Response\n",
    "from llama_index.indices.query.query_transform.feedback_transform import (\n",
    "    FeedbackQueryTransformation,\n",
    ")\n",
    "from llama_index.query_engine.retry_query_engine import (\n",
    "    RetryGuidelineQueryEngine,\n",
    ")\n",
    "\n",
    "# Guideline eval\n",
    "guideline_eval = GuidelineEvaluator(\n",
    "    guidelines=DEFAULT_GUIDELINES\n",
    "    + \"\\nThe response should not be overly long.\\n\"\n",
    "    \"The response should try to summarize where possible.\\n\"\n",
    ")  # just for example\n",
    "typed_response = response if isinstance(response, Response) else response.get_response()\n",
    "eval = guideline_eval.evaluate_response(query, typed_response)\n",
    "print(f\"Guideline eval evaluation result: {eval.feedback}\")\n",
    "feedback_query_transform = FeedbackQueryTransformation(resynthesize_query=True)\n",
    "transformed_query = feedback_query_transform.run(query, {\"evaluation\": eval})\n",
    "print(f\"Transformed query: {transformed_query.query_str}\")\n",
    "retry_guideline_query_engine = RetryGuidelineQueryEngine(\n",
    "    index.as_query_engine(), guideline_eval, resynthesize_query=True\n",
    ")\n",
    "retry_guideline_response = retry_guideline_query_engine.query(query)\n",
    "print(f\"Query engine with retry guideline response: {retry_guideline_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

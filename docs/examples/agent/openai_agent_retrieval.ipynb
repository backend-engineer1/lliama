{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Retrieval-Augmented OpenAI Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this tutorial, we show you how to use our `RetrieverOpenAI` implementation\n",
    "to build an agent on top of OpenAI's function API and store/index an arbitrary number of tools. Our indexing/retrieval modules help to remove the complexity of having too many functions to fit in the prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54b7bc2e-606f-411a-9490-fcfab9236dfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initial Setup "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23e80e5b-aaee-4f23-b338-7ae62b08141f",
   "metadata": {},
   "source": [
    "Let's start by importing some simple building blocks.  \n",
    "\n",
    "The main thing we need is:\n",
    "1. the OpenAI API (we will use langchain's ChatOpenAI wrapper for convienience here.)\n",
    "2. a place to keep conversation history \n",
    "3. a definition for tools that our agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c21e90-d59d-4010-9b1d-32e49e1d8f37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.agent.utils import FunctionMessage, monkey_patch_langchain\n",
    "\n",
    "# TODO: right now langchain does not support function messages\n",
    "#       monkey patch it to support it\n",
    "monkey_patch_langchain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d47283b-025e-4874-88ed-76245b22f82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from llama_index.tools import BaseTool, FunctionTool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fe08eb1-e638-4c00-9103-5c305bfacccf",
   "metadata": {},
   "source": [
    "Let's define some very simple calculator tools for our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd3c4a6-f3e0-46f9-ad3b-7ba57d1bc992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def useless(a: int, b: int) -> int:\n",
    "    \"\"\"Toy useless function.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply, name=\"multiply\")\n",
    "useless_tools = [FunctionTool.from_defaults(fn=useless, name=f\"useless_{str(idx)}\") for idx in range(28)]\n",
    "add_tool = FunctionTool.from_defaults(fn=add, name=\"add\")\n",
    "\n",
    "all_tools = [multiply_tool] + [add_tool] + useless_tools\n",
    "all_tools_map = {t.metadata.name: t for t in all_tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6704a755-7f05-43a3-8a56-f5f587ae4c40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding tool to index: multiply\n",
      "adding tool to index: add\n",
      "adding tool to index: useless_0\n",
      "adding tool to index: useless_1\n",
      "adding tool to index: useless_2\n",
      "adding tool to index: useless_3\n",
      "adding tool to index: useless_4\n",
      "adding tool to index: useless_5\n",
      "adding tool to index: useless_6\n",
      "adding tool to index: useless_7\n",
      "adding tool to index: useless_8\n",
      "adding tool to index: useless_9\n",
      "adding tool to index: useless_10\n",
      "adding tool to index: useless_11\n",
      "adding tool to index: useless_12\n",
      "adding tool to index: useless_13\n",
      "adding tool to index: useless_14\n",
      "adding tool to index: useless_15\n",
      "adding tool to index: useless_16\n",
      "adding tool to index: useless_17\n",
      "adding tool to index: useless_18\n",
      "adding tool to index: useless_19\n",
      "adding tool to index: useless_20\n",
      "adding tool to index: useless_21\n",
      "adding tool to index: useless_22\n",
      "adding tool to index: useless_23\n",
      "adding tool to index: useless_24\n",
      "adding tool to index: useless_25\n",
      "adding tool to index: useless_26\n",
      "adding tool to index: useless_27\n"
     ]
    }
   ],
   "source": [
    "# define an index over these tools\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.data_structs.node import Node\n",
    "import json\n",
    "\n",
    "# insert into index, define mapping function\n",
    "index = VectorStoreIndex([])\n",
    "for idx, (name, tool) in enumerate(all_tools_map.items()):\n",
    "    print(f'adding tool to index: {name}')\n",
    "    node_text = json.dumps(tool.metadata.to_openai_function())\n",
    "    node = Node(node_text, node_info={\"tool_name\": name})\n",
    "    index.insert_nodes([node])\n",
    "    \n",
    "    \n",
    "def node_to_tool_fn(node: Node):\n",
    "    \"\"\"Return tool given node.\"\"\"\n",
    "    openai_fn_dict = json.loads(node.get_text())\n",
    "    return all_tools_map[openai_fn_dict[\"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0625ae22-5d1e-4e24-a4cc-b183a4750710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retriever = index.as_retriever()\n",
    "# nodes = retriever.retrieve(\"get multiply fn\")\n",
    "# print(nodes)\n",
    "# tool = node_to_tool_fn(nodes[0].node)\n",
    "# print(tool)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "707d30b8-6405-4187-a9ed-6146dcc42167",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Our `RetrieverOpenAIAgent` Implementation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "798ca3fd-6711-4c0c-a853-d868dd14b484",
   "metadata": {},
   "source": [
    "We provide a (slightly better) `RetrieverOpenAIAgent` implementation in LlamaIndex, which you can directly use as follows.  \n",
    "\n",
    "In comparison to the simplified version above:\n",
    "* it implements the `BaseChatEngine` and `BaseQueryEngine` interface, so you can more seamlessly use it in the LlamaIndex framework. \n",
    "* it supports multiple function calls per conversation turn\n",
    "* it supports async endpoints\n",
    "* it supports callback and tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef8f729-790c-4dab-a06f-d9dee2003b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work with multi-function calls atm\n",
    "# NOTE: requires a bit of prompt tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ab3938-1138-43ea-b085-f430b42f5377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.agent import RetrieverOpenAIAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d852ece7-e5a1-4368-9d59-c7014e0b5b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = RetrieverOpenAIAgent.from_retriever(\n",
    "    index.as_retriever(),\n",
    "    node_to_tool_fn,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33ea069f-819b-4ec1-a93c-fcbaacb362a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 212,\n",
      "  \"b\": 122\n",
      "}\n",
      "Got output: 25864\n",
      "========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='The result of 212 multiplied by 122 is 25,864.', source_nodes=[], extra_info=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"What's 212 times 122? Make sure to use Tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec423b90-59cd-40ef-b497-a3842b3e7b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: add with args: {\n",
      "  \"a\": 212,\n",
      "  \"b\": 122\n",
      "}\n",
      "Got output: 334\n",
      "========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='The sum of 212 and 122 is 334.', source_nodes=[], extra_info=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"What's 212 added to 122 ? Make sure to use Tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d6522-df54-427c-9116-81d7e4ae9cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
